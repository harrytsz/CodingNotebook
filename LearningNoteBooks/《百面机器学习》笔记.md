
# 《百面机器学习--算法工程师带你去面试》

##  第 1 章 特征工程

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于一个机器学习问题，数据和特征往往决定了结果的上限，而模型、算法的选择及优化则是在逐步接近这个上限。“巧妇难为无米之炊”，在机器学习中，数据和特征是“米”，模型和算法则是“巧妇”。没有充足的数据、合适的特征，再强大的模型结构也无法得到满意的输出。正如一句业界经典的话所说，“Garbage in, Garbage out”。

**特征工程：**  顾名思义，是对原始数据进行一系列工程处理，将其提炼为特征，作为输入供算法和模型使用。从本质上来讲，特征工程是一个表示和展现数据的过程。在实际工作中，特征工程旨在去除原始数据中的杂质和冗余，设计更高效的特征以刻画求解的问题与预测模型之间的关系。

**结构化数据：** 结构化数据类型可以看作关系型数据库中的一张表，每列都有清晰的定义，包含了数值型、类别型两种基本类型；每一行数据表示一个样本的信息。

**非结构化数据：** 非结构化数据主要包括文本、图像、音频、视频数据，其包含的信息无法用一个简单的数值表示，也没有清晰的类别定义，并且每条数据的大小也各不相同。

###  1. 特征归一化

> **场景描述：**
>> 为了消除数据特征之间的量纲影响，我们需要对特征进行归一化处理，使得不同指标之间具有可比性。   
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;例如：分析一个人的身高和体重对健康的影响，如果使用米（m）和千克（kg）作为单位，那么身高特征会在1.6--1.8m的数值范围内，体重特征会在50--100kg的范围内，分析出来的结果显然会倾向于数值差别比较大的体重特征。想要得到更为准确的结果，就需要进行特征归一化（Normalization）处理，使得各指标处于同一数值量级，以便进行分析。

**Question 1：**  为什么需要对数值类型的特征做归一化？

#### **分析与解答：**

对于数值型的特征做归一化可以将所有的特征都统一到一个大致相同的数值区间内。最常用的方法主要有以下两种：  

（1）**线性函数归一化（Min-Max Scaling）:** 它对原始数据进行线性变换，使结果映射到[0, 1]的范围，实现对原始数据的等比缩放。

> **归一化公式如下：**  
>> X_{norm}= \frac{X-X_{min}}{X_{max}-X_{min}}   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (1.1) 

其中 X 为原始数据， X、X分别为数据最大值和最小值。

（2）**零均值归一化（Z-Score Normalization）:** 它会将原始数据映射到均值0、标准差为 1 的分布上。具体来说，假设原始特征的均值为$\mu $、标准差为$\sigma$.
>**归一化公式定义为：**    
>> z = \frac{x-\mu }{\sigma} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   (1.2)    

**为什么需要对数值型特征做归一化呢？**  
>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们不妨借助随机梯度下降的实例来说明归一化的重要性。假设有两种数值型特征，$x_{1}$ 的取值范围为[0, 10], $x_{2}$ 的取值范围为 [0, 3],于是可以构造一个目标函数符合图1.1（a）中的等值图。  
>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在学习率相同的情况下， $x_{1}$ 的更新速度会大于 $x_{2}$ ，需要较多的迭代才能找到最优解。如果将 $x_{1}$ 和 $x_{2}$ 归一化到相同的数值区间后，优化目标的等值图会变成图1.1（b）中的圆形， $x_{1}$ 和 $x_{2}$ 的更新速度变得更为一致，容易更快地通过梯度下降找到最优解。  

![normalization](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1536127304605&di=d70a58f075363e8ff5e205fa13ae7810&imgtype=0&src=http%3A%2F%2Fox5l2b8f4.bkt.clouddn.com%2Fimages%2F%25E6%25B7%25B1%25E5%25BA%25A6%25E5%25AD%25A6%25E4%25B9%25A0-%25E5%258A%25A0%25E5%25BF%25AB%25E5%25AD%25A6%25E4%25B9%25A0%25E9%2580%259F%25E5%25BA%25A6%2Fnormalize_input_1.png "归一化")
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（a）未归一化数据的梯度下降过程&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;（b）归一化数据的梯度下降过程
          <center>图1.1 数据归一化对梯度下降收敛速度产生的影响</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当然，数据归一化并不是万能的。在实际应用中，通过梯度下降法求解的模型通常需要归一化处理，包括线性回归、逻辑回归、支持向量机、神经网络等模型。但是对于决策树模型则并不适用，以C4.5为例，决策树在进行节点分裂时主要依据数据集D关于特征 x 的信息增益比，而信息增益比跟特征是否经过归一化是无关的，因为归一化并不会改变样本在特征 x 上的信息增益。
